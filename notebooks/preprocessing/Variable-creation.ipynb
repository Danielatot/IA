{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Variable creation",
   "id": "28e9426ea7b8984a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing libraries",
   "id": "bcb54c407c29d294"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:21.409338Z",
     "start_time": "2025-11-18T19:27:21.171847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from src.python import read_large_file, create_variable_eval, set_columns_to_datetime, extract_columns, \\\n",
    "    merge_similar_dfs, save_df_list_to_csv_auto\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'src', 'python')))\n",
    "from Functions import *"
   ],
   "id": "7c25c7dbb1b9c0b2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Importing the dataset\n",
    "We will use the less filler datasets for this notebook."
   ],
   "id": "4f92ab110b1c49b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:32.767369Z",
     "start_time": "2025-11-18T19:27:21.415261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing the dataset\n",
    "\n",
    "# Full financial year, all ja_kodas codes.\n",
    "oFFAJKA2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2025_full_financial_year_all.csv')\n",
    "oFFAJKA2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2024_full_financial_year_all.csv')\n",
    "oFFAJKA2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2023_full_financial_year_all.csv')\n",
    "oFFAJKA2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2022_full_financial_year_all.csv')\n",
    "oFFAJKA2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2021_full_financial_year_all.csv')\n",
    "oFFAJKA2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2020_full_financial_year_all.csv')\n",
    "\n",
    "# Full financial year, mathing ja_kodas codes.\n",
    "oFFAJKM2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2025_full_financial_year_matching.csv')\n",
    "oFFAJKM2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2024_full_financial_year_matching.csv')\n",
    "oFFAJKM2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2023_full_financial_year_matching.csv')\n",
    "oFFAJKM2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2022_full_financial_year_matching.csv')\n",
    "oFFAJKM2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2021_full_financial_year_matching.csv')\n",
    "oFFAJKM2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2020_full_financial_year_matching.csv')\n",
    "\n",
    "#New firms included, all ja_kodas codes.\n",
    "oNFAJKA2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2025_all_firms_all.csv')\n",
    "oNFAJKA2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2024_all_firms_all.csv')\n",
    "oNFAJKA2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2023_all_firms_all.csv')\n",
    "oNFAJKA2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2022_all_firms_all.csv')\n",
    "oNFAJKA2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2021_all_firms_all.csv')\n",
    "oNFAJKA2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2020_all_firms_all.csv')\n",
    "\n",
    "#New firms included, matching ja_kodas codes.\n",
    "oNFAJKM2025 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2025_all_firms_matching.csv')\n",
    "oNFAJKM2024 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2024_all_firms_matching.csv')\n",
    "oNFAJKM2023 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2023_all_firms_matching.csv')\n",
    "oNFAJKM2022 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2022_all_firms_matching.csv')\n",
    "oNFAJKM2021 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2021_all_firms_matching.csv')\n",
    "oNFAJKM2020 = read_large_file('../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2020_all_firms_matching.csv')\n",
    "\n",
    "# Address data\n",
    "\n",
    "Address = pd.read_excel('../../data/raw/firm-adress-data/JAR_ADRESAI_su_apskritimis.xlsx')\n",
    "\n"
   ],
   "id": "863b964ecde35cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2025_full_financial_year_all.csv\n",
      "File size: 20.21 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 2531 rows (total: 132531)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 132531\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2024_full_financial_year_all.csv\n",
      "File size: 19.32 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 6352 rows (total: 126352)\n",
      "Concatenating 13 chunks...\n",
      "Finished reading. Total rows: 126352\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2023_full_financial_year_all.csv\n",
      "File size: 18.27 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 5097 rows (total: 125097)\n",
      "Concatenating 13 chunks...\n",
      "Finished reading. Total rows: 125097\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2022_full_financial_year_all.csv\n",
      "File size: 11.91 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 7033 rows (total: 107033)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 107033\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2021_full_financial_year_all.csv\n",
      "File size: 13.90 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 4514 rows (total: 94514)\n",
      "Concatenating 10 chunks...\n",
      "Finished reading. Total rows: 94514\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/full_financial_year/Merged2020_full_financial_year_all.csv\n",
      "File size: 12.81 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 6742 rows (total: 86742)\n",
      "Concatenating 9 chunks...\n",
      "Finished reading. Total rows: 86742\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2025_full_financial_year_matching.csv\n",
      "File size: 19.53 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 384 rows (total: 130384)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 130384\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2024_full_financial_year_matching.csv\n",
      "File size: 18.68 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.05}\n",
      "Detected delimiter: ',' (score: 16.05)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 4484 rows (total: 124484)\n",
      "Concatenating 13 chunks...\n",
      "Finished reading. Total rows: 124484\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2023_full_financial_year_matching.csv\n",
      "File size: 15.78 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.15}\n",
      "Detected delimiter: ',' (score: 16.15)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 5929 rows (total: 105929)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 105929\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2022_full_financial_year_matching.csv\n",
      "File size: 0.98 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 6911 rows (total: 6911)\n",
      "Concatenating 1 chunks...\n",
      "Finished reading. Total rows: 6911\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2021_full_financial_year_matching.csv\n",
      "File size: 13.00 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 6395 rows (total: 86395)\n",
      "Concatenating 9 chunks...\n",
      "Finished reading. Total rows: 86395\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/full_financial_year/Merged2020_full_financial_year_matching.csv\n",
      "File size: 12.00 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 9357 rows (total: 79357)\n",
      "Concatenating 8 chunks...\n",
      "Finished reading. Total rows: 79357\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2025_all_firms_all.csv\n",
      "File size: 21.89 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 10000 rows (total: 140000)\n",
      "Processed chunk 15 with 4336 rows (total: 144336)\n",
      "Concatenating 15 chunks...\n",
      "Finished reading. Total rows: 144336\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2024_all_firms_all.csv\n",
      "File size: 21.05 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 8564 rows (total: 138564)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 138564\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2023_all_firms_all.csv\n",
      "File size: 19.80 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 6578 rows (total: 136578)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 136578\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2022_all_firms_all.csv\n",
      "File size: 16.88 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 6768 rows (total: 116768)\n",
      "Concatenating 12 chunks...\n",
      "Finished reading. Total rows: 116768\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2021_all_firms_all.csv\n",
      "File size: 15.13 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 3744 rows (total: 103744)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 103744\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/all-ja_kodas/with_new_firms/Merged2020_all_firms_all.csv\n",
      "File size: 13.90 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 4664 rows (total: 94664)\n",
      "Concatenating 10 chunks...\n",
      "Finished reading. Total rows: 94664\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2025_all_firms_matching.csv\n",
      "File size: 21.17 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 10000 rows (total: 140000)\n",
      "Processed chunk 15 with 2174 rows (total: 142174)\n",
      "Concatenating 15 chunks...\n",
      "Finished reading. Total rows: 142174\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2024_all_firms_matching.csv\n",
      "File size: 20.37 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.05}\n",
      "Detected delimiter: ',' (score: 16.05)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 10000 rows (total: 120000)\n",
      "Processed chunk 13 with 10000 rows (total: 130000)\n",
      "Processed chunk 14 with 6680 rows (total: 136680)\n",
      "Concatenating 14 chunks...\n",
      "Finished reading. Total rows: 136680\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2023_all_firms_matching.csv\n",
      "File size: 17.10 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.05}\n",
      "Detected delimiter: ',' (score: 16.05)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 10000 rows (total: 110000)\n",
      "Processed chunk 12 with 5651 rows (total: 115651)\n",
      "Concatenating 12 chunks...\n",
      "Finished reading. Total rows: 115651\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2022_all_firms_matching.csv\n",
      "File size: 15.63 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 10000 rows (total: 100000)\n",
      "Processed chunk 11 with 5324 rows (total: 105324)\n",
      "Concatenating 11 chunks...\n",
      "Finished reading. Total rows: 105324\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2021_all_firms_matching.csv\n",
      "File size: 14.19 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 10000 rows (total: 90000)\n",
      "Processed chunk 10 with 5060 rows (total: 95060)\n",
      "Concatenating 10 chunks...\n",
      "Finished reading. Total rows: 95060\n",
      "Reading CSV file from: ../../data/interim/joined-balance-and-PnL-no-filler/only-matching-ja_kodas/with_new_firms/Merged2020_all_firms_matching.csv\n",
      "File size: 13.04 MB\n",
      "Auto-detecting CSV delimiter...\n",
      "Delimiter detection scores: {',': 16.0}\n",
      "Detected delimiter: ',' (score: 16.00)\n",
      "Bad lines handling: error\n",
      "File encoding: utf-8\n",
      "Processed chunk 1 with 10000 rows (total: 10000)\n",
      "Processed chunk 2 with 10000 rows (total: 20000)\n",
      "Processed chunk 3 with 10000 rows (total: 30000)\n",
      "Processed chunk 4 with 10000 rows (total: 40000)\n",
      "Processed chunk 5 with 10000 rows (total: 50000)\n",
      "Processed chunk 6 with 10000 rows (total: 60000)\n",
      "Processed chunk 7 with 10000 rows (total: 70000)\n",
      "Processed chunk 8 with 10000 rows (total: 80000)\n",
      "Processed chunk 9 with 6838 rows (total: 86838)\n",
      "Concatenating 9 chunks...\n",
      "Finished reading. Total rows: 86838\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Making copies of the dataframes\n",
    "We will make copies of the dataframes to avoid any unwanted modifications to the original dataframes."
   ],
   "id": "51fba313153a5539"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:33.213483Z",
     "start_time": "2025-11-18T19:27:32.881207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making copies of the dataframes\n",
    "\n",
    "# Full financial year, all ja_kodas codes.\n",
    "\n",
    "FFAJKA2025 = oFFAJKA2025.copy()\n",
    "FFAJKA2024 = oFFAJKA2024.copy()\n",
    "FFAJKA2023 = oFFAJKA2023.copy()\n",
    "FFAJKA2022 = oFFAJKA2022.copy()\n",
    "FFAJKA2021 = oFFAJKA2021.copy()\n",
    "FFAJKA2020 = oFFAJKA2020.copy()\n",
    "\n",
    "# Full financial year, matching ja_kodas codes.\n",
    "\n",
    "FFAJKM2025 = oFFAJKM2025.copy()\n",
    "FFAJKM2024 = oFFAJKM2024.copy()\n",
    "FFAJKM2023 = oFFAJKM2023.copy()\n",
    "FFAJKM2022 = oFFAJKM2022.copy()\n",
    "FFAJKM2021 = oFFAJKM2021.copy()\n",
    "FFAJKM2020 = oFFAJKM2020.copy()\n",
    "\n",
    "#New firms included, all ja_kodas codes.\n",
    "\n",
    "NFAJKA2025 = oNFAJKA2025.copy()\n",
    "NFAJKA2024 = oNFAJKA2024.copy()\n",
    "NFAJKA2023 = oNFAJKA2023.copy()\n",
    "NFAJKA2022 = oNFAJKA2022.copy()\n",
    "NFAJKA2021 = oNFAJKA2021.copy()\n",
    "NFAJKA2020 = oNFAJKA2020.copy()\n",
    "\n",
    "#New firms included, matching ja_kodas codes.\n",
    "\n",
    "NFAJKM2025 = oNFAJKM2025.copy()\n",
    "NFAJKM2024 = oNFAJKM2024.copy()\n",
    "NFAJKM2023 = oNFAJKM2023.copy()\n",
    "NFAJKM2022 = oNFAJKM2022.copy()\n",
    "NFAJKM2021 = oNFAJKM2021.copy()\n",
    "NFAJKM2020 = oNFAJKM2020.copy()\n",
    "\n",
    "# Saving in lists for ease of use.\n",
    "\n",
    "FFAJKA = [FFAJKA2025, FFAJKA2024, FFAJKA2023, FFAJKA2022, FFAJKA2021, FFAJKA2020]\n",
    "FFAJKM = [FFAJKM2025, FFAJKM2024, FFAJKM2023, FFAJKM2022, FFAJKM2021, FFAJKM2020]\n",
    "NFAJKA = [NFAJKA2025, NFAJKA2024, NFAJKA2023, NFAJKA2022, NFAJKA2021, NFAJKA2020]\n",
    "NFAJKM = [NFAJKM2025, NFAJKM2024, NFAJKM2023, NFAJKM2022, NFAJKM2021, NFAJKM2020]\n",
    "\n",
    "ALL_DATA = [FFAJKA, FFAJKM, NFAJKA, NFAJKM]"
   ],
   "id": "666a37025fb506f4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating variables\n",
   "id": "bf8e6297f90f8884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:33.690078Z",
     "start_time": "2025-11-18T19:27:33.220914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# TURTAS variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'TURTAS', '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`')\n",
    "\n",
    "# GRYNOJO PELNO MARZA variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'GRYNOJO PELNO MARŽA (procentais)', '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100')\n",
    "\n",
    "# TURTO APYVARTUMAS variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'TURTO APYVARTUMAS (santykis)', '`TURTAS` / `PARDAVIMO PAJAMOS`')\n",
    "\n",
    "# ROA variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'ROA (procentais)', '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100')\n",
    "\n",
    "# VĖLUOJANČIOS ATASKAITOS variable, reg_date of pnl or balance is after 05-30\n",
    "Y2025 = [FFAJKA2025, FFAJKM2025, NFAJKA2025, NFAJKM2025]\n",
    "Y2024 = [FFAJKA2024, FFAJKM2024, NFAJKA2024, NFAJKM2024]\n",
    "Y2023 = [FFAJKA2023, FFAJKM2023, NFAJKA2023, NFAJKM2023]\n",
    "Y2022 = [FFAJKA2022, FFAJKM2022, NFAJKA2022, NFAJKM2022]\n",
    "Y2021 = [FFAJKA2021, FFAJKM2021, NFAJKA2021, NFAJKM2021]\n",
    "Y2020 = [FFAJKA2020, FFAJKM2020, NFAJKA2020, NFAJKM2020]\n",
    "\n",
    "set_columns_to_datetime(Y2025, ['reg_date_pnl', 'reg_date_balance'], inplace=True)\n",
    "\n",
    "create_variable_eval(Y2025, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")')\n",
    "create_variable_eval(Y2024, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")')\n",
    "create_variable_eval(Y2023, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")')\n",
    "create_variable_eval(Y2022, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")')\n",
    "create_variable_eval(Y2021, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")')\n",
    "create_variable_eval(Y2020, 'VĖLUOJANČIOS ATASKAITOS', '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")')\n",
    "\n",
    "\n",
    "# SVERTINIS MOKUMO PAKAITALAS variable\n",
    "\n",
    "create_variable_eval(ALL_DATA, 'SVERTINIS MOKUMO PAKAITALAS (santykis)', '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`')\n",
    "\n"
   ],
   "id": "a8acec94d65bf247",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [0, 5]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [1, 5]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [2, 5]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 0]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 1]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 2]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 3]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 4]\n",
      "✓ Modified DataFrame with formula '`ILGALAIKIS TURTAS` + `TRUMPALAIKIS TURTAS`' -> 'TURTAS' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `PARDAVIMO PAJAMOS`) * 100' -> 'GRYNOJO PELNO MARŽA (procentais)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '`TURTAS` / `PARDAVIMO PAJAMOS`' -> 'TURTO APYVARTUMAS (santykis)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '(`GRYNASIS PELNAS (NUOSTOLIAI)` / `TURTAS`) * 100' -> 'ROA (procentais)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n",
      "⚠️  INPLACE MODE: Modifying original DataFrame(s)\n",
      "\n",
      "Processing DataFrame 0 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "\n",
      "Processing DataFrame 1 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "\n",
      "Processing DataFrame 2 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "\n",
      "Processing DataFrame 3 in place\n",
      "Converted column 'reg_date_pnl' to datetime\n",
      "Converted column 'reg_date_balance' to datetime\n",
      "📊 Inplace processing: Converted 2, Skipped 0, Dropped 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2025-04-30\") | (`reg_date_balance` > \"2025-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2024-04-30\") | (`reg_date_balance` > \"2024-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2023-04-30\") | (`reg_date_balance` > \"2023-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2022-04-30\") | (`reg_date_balance` > \"2022-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2021-04-30\") | (`reg_date_balance` > \"2021-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [0]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [1]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [2]\n",
      "✓ Modified DataFrame with formula '(`reg_date_pnl` > \"2020-04-30\") | (`reg_date_balance` > \"2020-04-30\")' -> 'VĖLUOJANČIOS ATASKAITOS' at [3]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 4\n",
      "Successful: 4 (100.0%)\n",
      "Failed: 0\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [0, 5]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [1, 5]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [2, 5]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 0]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 1]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 2]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 3]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 4]\n",
      "✓ Modified DataFrame with formula '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`' -> 'SVERTINIS MOKUMO PAKAITALAS (santykis)' at [3, 5]\n",
      "\n",
      "=== IN-PLACE OPERATION SUMMARY ===\n",
      "Total processed: 24\n",
      "Successful: 24 (100.0%)\n",
      "Failed: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_processed': 24,\n",
       " 'successful': 24,\n",
       " 'failed': 0,\n",
       " 'errors': [],\n",
       " 'formula_used': '`MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI` / `TURTAS`',\n",
       " 'inplace': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Merging date columns\n",
    "My coalescing function cannot take list of list so we insert just lists of dataframes."
   ],
   "id": "c44006c3dced40d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:35.597348Z",
     "start_time": "2025-11-18T19:27:33.699466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Merging date columns\n",
    "\n",
    "## New firms included.\n",
    "\n",
    "# beginning and turning date\n",
    "coalesce_columns(NFAJKA, ['beginning_date_balance', 'beginning_date_pnl'], 'beginning_date')\n",
    "coalesce_columns(NFAJKM, ['beginning_date_balance', 'beginning_date_pnl'], 'beginning_date')\n",
    "\n",
    "coalesce_columns(NFAJKA, ['turning_date_balance', 'turning_date_pnl'], 'turning_date')\n",
    "coalesce_columns(NFAJKM, ['turning_date_balance', 'turning_date_pnl'], 'turning_date')\n",
    "\n",
    "# Merging reg_date_balance and reg_date_pnl for simplicity\n",
    "\n",
    "coalesce_columns(NFAJKA, ['reg_date_balance','reg_date_pnl'], 'reg_date')\n",
    "coalesce_columns(NFAJKM, ['reg_date_balance','reg_date_pnl'], 'reg_date')\n",
    "\n",
    "## Full financial year data\n",
    "\n",
    "# beginning and turning date\n",
    "coalesce_columns(FFAJKA, ['beginning_date_balance', 'beginning_date_pnl'], 'beginning_date')\n",
    "coalesce_columns(FFAJKM, ['beginning_date_balance', 'beginning_date_pnl'], 'beginning_date')\n",
    "\n",
    "coalesce_columns(FFAJKA, ['turning_date_balance', 'turning_date_pnl'], 'turning_date')\n",
    "coalesce_columns(FFAJKM, ['turning_date_balance', 'turning_date_pnl'], 'turning_date')\n",
    "\n",
    "# Merging reg_date_balance and reg_date_pnl for simplicity\n",
    "\n",
    "coalesce_columns(FFAJKA, ['reg_date_balance','reg_date_pnl'], 'reg_date')\n",
    "coalesce_columns(FFAJKM, ['reg_date_balance','reg_date_pnl'], 'reg_date')\n"
   ],
   "id": "a1db2f6a076ec34e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 0\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 1\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 2\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 3\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 4\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 5\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 0\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 1\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 2\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 3\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 4\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 5\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 0\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 1\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 2\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 3\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 4\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 5\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 0\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 1\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 2\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 3\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 4\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 5\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 0\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 1\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 2\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 3\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 4\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 5\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 0\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 1\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 2\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 3\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 4\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 5\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 0\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 1\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 2\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 3\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 4\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 5\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 0\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 1\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 2\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 3\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 4\n",
      "Coalesced columns ['beginning_date_balance', 'beginning_date_pnl'] -> 'beginning_date' in DataFrame 5\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 0\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 1\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 2\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 3\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 4\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 5\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 0\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 1\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 2\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 3\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 4\n",
      "Coalesced columns ['turning_date_balance', 'turning_date_pnl'] -> 'turning_date' in DataFrame 5\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 0\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 1\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 2\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 3\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 4\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 5\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 0\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 1\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 2\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 3\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 4\n",
      "Coalesced columns ['reg_date_balance', 'reg_date_pnl'] -> 'reg_date' in DataFrame 5\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ddd6dccc05748ddb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adding address data to variables",
   "id": "565d7921e35bf4e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:35.759623Z",
     "start_time": "2025-11-18T19:27:35.738086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extracting address data\n",
    "\n",
    "extraction_cols = ['ja_kodas', 'adresas', 'Apskritis']\n",
    "\n",
    "add_df = extract_columns(Address, extraction_cols)"
   ],
   "id": "c8aa6e3056ab7079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0: Extracted 3 columns, processed shape: (222198, 7)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merging address data to variables on ja_kodas",
   "id": "d55292e5e19622d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:38.775467Z",
     "start_time": "2025-11-18T19:27:35.799781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "## New firms included.\n",
    "NFAJKA_with_address = merge_similar_dfs(NFAJKA, add_df, 'ja_kodas', how='left')\n",
    "NFAJKM_with_address = merge_similar_dfs(NFAJKM, add_df, 'ja_kodas', how='left')\n",
    "## Full financial year data\n",
    "FFAJKA_with_address = merge_similar_dfs(FFAJKA, add_df, 'ja_kodas', how='left')\n",
    "FFAJKM_with_address = merge_similar_dfs(FFAJKM, add_df, 'ja_kodas', how='left')\n",
    "\n",
    "##\n"
   ],
   "id": "c24d537273a6ceb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: List lengths differ - list1: 6, list2: 1\n",
      "Repeating single DF2 6 times to match DF1 list\n",
      "🔗 MERGE CONFIGURATION:\n",
      "   📊 Input pairs: 6\n",
      "   🎯 Merge column: 'ja_kodas'\n",
      "   🔄 Merge type: left\n",
      "   📝 Suffixes: None\n",
      "   ✅ Validate: None\n",
      "   📈 Indicator: None\n",
      "   🔄 Duplicate handling: None\n",
      "   🚫 NaN handling: None\n",
      "   🔧 Dtype conversion: auto\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 144336 rows, 144336 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 143520\n",
      "Merge type: left\n",
      "Expected result rows: 144336\n",
      "Actual result rows: 144336\n",
      "Pair 0: Successfully merged. Shapes: (144336, 20) + (222198, 3) -> (144336, 22)\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 138564 rows, 138564 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 136292\n",
      "Merge type: left\n",
      "Expected result rows: 138564\n",
      "Actual result rows: 138564\n",
      "Pair 1: Successfully merged. Shapes: (138564, 20) + (222198, 3) -> (138564, 22)\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 136578 rows, 136578 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 132372\n",
      "Merge type: left\n",
      "Expected result rows: 136578\n",
      "Actual result rows: 136578\n",
      "Pair 2: Successfully merged. Shapes: (136578, 20) + (222198, 3) -> (136578, 22)\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 116768 rows, 116768 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 111618\n",
      "Merge type: left\n",
      "Expected result rows: 116768\n",
      "Actual result rows: 116768\n",
      "Pair 3: Successfully merged. Shapes: (116768, 20) + (222198, 3) -> (116768, 22)\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 103744 rows, 103744 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 95835\n",
      "Merge type: left\n",
      "Expected result rows: 103744\n",
      "Actual result rows: 103744\n",
      "Pair 4: Successfully merged. Shapes: (103744, 20) + (222198, 3) -> (103744, 22)\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 94664 rows, 94664 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 85009\n",
      "Merge type: left\n",
      "Expected result rows: 94664\n",
      "Actual result rows: 94664\n",
      "Pair 5: Successfully merged. Shapes: (94664, 20) + (222198, 3) -> (94664, 22)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "✅ Successful merges: 6/6\n",
      "📊 Total output DataFrames: 6\n",
      "Warning: List lengths differ - list1: 6, list2: 1\n",
      "Repeating single DF2 6 times to match DF1 list\n",
      "🔗 MERGE CONFIGURATION:\n",
      "   📊 Input pairs: 6\n",
      "   🎯 Merge column: 'ja_kodas'\n",
      "   🔄 Merge type: left\n",
      "   📝 Suffixes: None\n",
      "   ✅ Validate: None\n",
      "   📈 Indicator: None\n",
      "   🔄 Duplicate handling: None\n",
      "   🚫 NaN handling: None\n",
      "   🔧 Dtype conversion: auto\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 142174 rows, 142174 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 141443\n",
      "Merge type: left\n",
      "Expected result rows: 142174\n",
      "Actual result rows: 142174\n",
      "Pair 0: Successfully merged. Shapes: (142174, 20) + (222198, 3) -> (142174, 22)\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 136680 rows, 136680 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 134556\n",
      "Merge type: left\n",
      "Expected result rows: 136680\n",
      "Actual result rows: 136680\n",
      "Pair 1: Successfully merged. Shapes: (136680, 20) + (222198, 3) -> (136680, 22)\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 115651 rows, 115651 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 112071\n",
      "Merge type: left\n",
      "Expected result rows: 115651\n",
      "Actual result rows: 115651\n",
      "Pair 2: Successfully merged. Shapes: (115651, 20) + (222198, 3) -> (115651, 22)\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 105324 rows, 105324 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 100690\n",
      "Merge type: left\n",
      "Expected result rows: 105324\n",
      "Actual result rows: 105324\n",
      "Pair 3: Successfully merged. Shapes: (105324, 20) + (222198, 3) -> (105324, 22)\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 95060 rows, 95060 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 87801\n",
      "Merge type: left\n",
      "Expected result rows: 95060\n",
      "Actual result rows: 95060\n",
      "Pair 4: Successfully merged. Shapes: (95060, 20) + (222198, 3) -> (95060, 22)\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 86838 rows, 86838 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 77868\n",
      "Merge type: left\n",
      "Expected result rows: 86838\n",
      "Actual result rows: 86838\n",
      "Pair 5: Successfully merged. Shapes: (86838, 20) + (222198, 3) -> (86838, 22)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "✅ Successful merges: 6/6\n",
      "📊 Total output DataFrames: 6\n",
      "Warning: List lengths differ - list1: 6, list2: 1\n",
      "Repeating single DF2 6 times to match DF1 list\n",
      "🔗 MERGE CONFIGURATION:\n",
      "   📊 Input pairs: 6\n",
      "   🎯 Merge column: 'ja_kodas'\n",
      "   🔄 Merge type: left\n",
      "   📝 Suffixes: None\n",
      "   ✅ Validate: None\n",
      "   📈 Indicator: None\n",
      "   🔄 Duplicate handling: None\n",
      "   🚫 NaN handling: None\n",
      "   🔧 Dtype conversion: auto\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 132531 rows, 132531 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 131779\n",
      "Merge type: left\n",
      "Expected result rows: 132531\n",
      "Actual result rows: 132531\n",
      "Pair 0: Successfully merged. Shapes: (132531, 20) + (222198, 3) -> (132531, 22)\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 126352 rows, 126352 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 124265\n",
      "Merge type: left\n",
      "Expected result rows: 126352\n",
      "Actual result rows: 126352\n",
      "Pair 1: Successfully merged. Shapes: (126352, 20) + (222198, 3) -> (126352, 22)\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 125097 rows, 125097 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 121279\n",
      "Merge type: left\n",
      "Expected result rows: 125097\n",
      "Actual result rows: 125097\n",
      "Pair 2: Successfully merged. Shapes: (125097, 20) + (222198, 3) -> (125097, 22)\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 107033 rows, 107033 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 102196\n",
      "Merge type: left\n",
      "Expected result rows: 107033\n",
      "Actual result rows: 107033\n",
      "Pair 3: Successfully merged. Shapes: (107033, 20) + (222198, 3) -> (107033, 22)\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 94514 rows, 94514 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 87504\n",
      "Merge type: left\n",
      "Expected result rows: 94514\n",
      "Actual result rows: 94514\n",
      "Pair 4: Successfully merged. Shapes: (94514, 20) + (222198, 3) -> (94514, 22)\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 86742 rows, 86742 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 78105\n",
      "Merge type: left\n",
      "Expected result rows: 86742\n",
      "Actual result rows: 86742\n",
      "Pair 5: Successfully merged. Shapes: (86742, 20) + (222198, 3) -> (86742, 22)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "✅ Successful merges: 6/6\n",
      "📊 Total output DataFrames: 6\n",
      "Warning: List lengths differ - list1: 6, list2: 1\n",
      "Repeating single DF2 6 times to match DF1 list\n",
      "🔗 MERGE CONFIGURATION:\n",
      "   📊 Input pairs: 6\n",
      "   🎯 Merge column: 'ja_kodas'\n",
      "   🔄 Merge type: left\n",
      "   📝 Suffixes: None\n",
      "   ✅ Validate: None\n",
      "   📈 Indicator: None\n",
      "   🔄 Duplicate handling: None\n",
      "   🚫 NaN handling: None\n",
      "   🔧 Dtype conversion: auto\n",
      "\n",
      "--- Pair 0 Merge Diagnostics ---\n",
      "DF1: 130384 rows, 130384 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 129715\n",
      "Merge type: left\n",
      "Expected result rows: 130384\n",
      "Actual result rows: 130384\n",
      "Pair 0: Successfully merged. Shapes: (130384, 20) + (222198, 3) -> (130384, 22)\n",
      "\n",
      "--- Pair 1 Merge Diagnostics ---\n",
      "DF1: 124484 rows, 124484 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 122538\n",
      "Merge type: left\n",
      "Expected result rows: 124484\n",
      "Actual result rows: 124484\n",
      "Pair 1: Successfully merged. Shapes: (124484, 20) + (222198, 3) -> (124484, 22)\n",
      "\n",
      "--- Pair 2 Merge Diagnostics ---\n",
      "DF1: 105929 rows, 105929 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 102680\n",
      "Merge type: left\n",
      "Expected result rows: 105929\n",
      "Actual result rows: 105929\n",
      "Pair 2: Successfully merged. Shapes: (105929, 20) + (222198, 3) -> (105929, 22)\n",
      "\n",
      "--- Pair 3 Merge Diagnostics ---\n",
      "DF1: 6911 rows, 6911 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 6416\n",
      "Merge type: left\n",
      "Expected result rows: 6911\n",
      "Actual result rows: 6911\n",
      "Pair 3: Successfully merged. Shapes: (6911, 20) + (222198, 3) -> (6911, 22)\n",
      "\n",
      "--- Pair 4 Merge Diagnostics ---\n",
      "DF1: 86395 rows, 86395 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 79902\n",
      "Merge type: left\n",
      "Expected result rows: 86395\n",
      "Actual result rows: 86395\n",
      "Pair 4: Successfully merged. Shapes: (86395, 20) + (222198, 3) -> (86395, 22)\n",
      "\n",
      "--- Pair 5 Merge Diagnostics ---\n",
      "DF1: 79357 rows, 79357 unique ja_kodas\n",
      "DF2: 222198 rows, 222198 unique ja_kodas\n",
      "Common ja_kodas: 71366\n",
      "Merge type: left\n",
      "Expected result rows: 79357\n",
      "Actual result rows: 79357\n",
      "Pair 5: Successfully merged. Shapes: (79357, 20) + (222198, 3) -> (79357, 22)\n",
      "\n",
      "=== MERGE SUMMARY ===\n",
      "✅ Successful merges: 6/6\n",
      "📊 Total output DataFrames: 6\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rearranging columns\n",
   "id": "401d717e9316d8db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:27:39.415469Z",
     "start_time": "2025-11-18T19:27:38.939779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Rearranging columns\n",
    "# List all columns\n",
    "FFAJKA_with_address[0].columns\n",
    "\n",
    "patterns = {\n",
    "    'identifier': ['ja_kodas', 'ja_pavadinimas','stat_kodas', 'form_kodas'],\n",
    "    'company_info': ['Apskritis', 'adresas'],\n",
    "    'dates': ['beginning_date', 'turning_date', 'reg_date', 'VĖLUOJANČIOS ATASKAITOS'],\n",
    "    'assets': ['ILGALAIKIS TURTAS', 'TRUMPALAIKIS TURTAS', 'TURTAS'],\n",
    "    'financial_liabilities': ['MOKĖTINOS SUMOS IR KITI ĮSIPAREIGOJIMAI', 'NUOSAVAS KAPITALAS'],\n",
    "    'income': ['PARDAVIMO PAJAMOS'],\n",
    "    'profitability': ['GRYNASIS PELNAS (NUOSTOLIAI)', 'PELNAS (NUOSTOLIAI) PRIEŠ APMOKESTINIMĄ', 'GRYNOJO PELNO MARŽA', 'ROA'],\n",
    "    'ratios': ['TURTO APYVARTUMAS', 'SVERTINIS MOKUMO PAKAITALAS']\n",
    "}\n",
    "\n",
    "order = ['identifier', 'company_info', 'dates', 'assets', 'financial_liabilities', 'income', 'profitability', 'ratios']\n",
    "\n",
    "NFAJKA_with_address = rearrange_columns_smart(\n",
    "    NFAJKA_with_address,\n",
    "    patterns=patterns,\n",
    "    priority_cols=['ja_kodas', 'ja_pavadinimas'],  # Put these first within identifier group\n",
    "    group_order=order,\n",
    ")\n",
    "\n",
    "NFAJKM_with_address = rearrange_columns_smart(\n",
    "    NFAJKM_with_address,\n",
    "    patterns=patterns,\n",
    "    priority_cols=['ja_kodas', 'ja_pavadinimas'],  # Put these first within identifier group\n",
    "    group_order=order,\n",
    ")\n",
    "\n",
    "FFAJKA_rearranged = rearrange_columns_smart(\n",
    "    FFAJKA_with_address,\n",
    "    patterns=patterns,\n",
    "    priority_cols=['ja_kodas', 'ja_pavadinimas'],  # Put these first within identifier group\n",
    "    group_order=order,\n",
    ")\n",
    "\n",
    "FFAJKM_rearranged = rearrange_columns_smart(\n",
    "    FFAJKM_with_address,\n",
    "    patterns=patterns,\n",
    "    priority_cols=['ja_kodas', 'ja_pavadinimas'],  # Put these first within identifier group\n",
    "    group_order=order,\n",
    ")\n"
   ],
   "id": "138da41d4b648957",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4f4bb496a86d725d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving dataframes without YoY change to csv files\n",
   "id": "54780d375dda3748"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T19:28:01.031640Z",
     "start_time": "2025-11-18T19:27:39.426468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Saving dataframes\n",
    "\n",
    "## FFAJKA\n",
    "\n",
    "Full_Financial_Year_All_ja_kodas_2025 = FFAJKA_rearranged[0]\n",
    "Full_Financial_Year_All_ja_kodas_2024 = FFAJKA_rearranged[1]\n",
    "Full_Financial_Year_All_ja_kodas_2023 = FFAJKA_rearranged[2]\n",
    "Full_Financial_Year_All_ja_kodas_2022 = FFAJKA_rearranged[3]\n",
    "Full_Financial_Year_All_ja_kodas_2021 = FFAJKA_rearranged[4]\n",
    "Full_Financial_Year_All_ja_kodas_2020 = FFAJKA_rearranged[5]\n",
    "\n",
    "save_df_list_to_csv_auto(FFAJKA_rearranged, '../../data/processed/Financial-tables/No-YoY-change/Full-financial-year/All-ja_kodas')\n",
    "\n",
    "## FFAJKM\n",
    "\n",
    "Full_Financial_Year_Matching_ja_kodas_2025 = FFAJKM_rearranged[0]\n",
    "Full_Financial_Year_Matching_ja_kodas_2024 = FFAJKM_rearranged[1]\n",
    "Full_Financial_Year_Matching_ja_kodas_2023 = FFAJKM_rearranged[2]\n",
    "Full_Financial_Year_Matching_ja_kodas_2022 = FFAJKM_rearranged[3]\n",
    "Full_Financial_Year_Matching_ja_kodas_2021 = FFAJKM_rearranged[4]\n",
    "Full_Financial_Year_Matching_ja_kodas_2020 = FFAJKM_rearranged[5]\n",
    "\n",
    "save_df_list_to_csv_auto(FFAJKM_rearranged, '../../data/processed/Financial-tables/No-YoY-change/Full-financial-year/Only-matching-ja_kodas')\n",
    "\n",
    "## NFAJKA\n",
    "\n",
    "New_Firms_All_ja_kodas_2025 = NFAJKA_with_address[0]\n",
    "New_Firms_All_ja_kodas_2024 = NFAJKA_with_address[1]\n",
    "New_Firms_All_ja_kodas_2023 = NFAJKA_with_address[2]\n",
    "New_Firms_All_ja_kodas_2022 = NFAJKA_with_address[3]\n",
    "New_Firms_All_ja_kodas_2021 = NFAJKA_with_address[4]\n",
    "New_Firms_All_ja_kodas_2020 = NFAJKA_with_address[5]\n",
    "\n",
    "save_df_list_to_csv_auto(NFAJKA_with_address, '../../data/processed/Financial-tables/No-YoY-change/With-new-firms/All-ja_kodas')\n",
    "\n",
    "## NFAJKM\n",
    "\n",
    "New_Firms_Matching_ja_kodas_2025 = NFAJKM_with_address[0]\n",
    "New_Firms_Matching_ja_kodas_2024 = NFAJKM_with_address[1]\n",
    "New_Firms_Matching_ja_kodas_2023 = NFAJKM_with_address[2]\n",
    "New_Firms_Matching_ja_kodas_2022 = NFAJKM_with_address[3]\n",
    "New_Firms_Matching_ja_kodas_2021 = NFAJKM_with_address[4]\n",
    "New_Firms_Matching_ja_kodas_2020 = NFAJKM_with_address[5]\n",
    "\n",
    "save_df_list_to_csv_auto(NFAJKM_with_address, '../../data/processed/Financial-tables/No-YoY-change/With-new-firms/Only-matching-ja_kodas')"
   ],
   "id": "d17168b02c1110b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New_Firms_Matching_ja_kodas_2025',\n",
       " 'New_Firms_Matching_ja_kodas_2024',\n",
       " 'New_Firms_Matching_ja_kodas_2023',\n",
       " 'New_Firms_Matching_ja_kodas_2022',\n",
       " 'New_Firms_Matching_ja_kodas_2021',\n",
       " 'New_Firms_Matching_ja_kodas_2020']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
